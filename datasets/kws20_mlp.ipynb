{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "from scipy.signal import get_window\n",
    "import scipy.fftpack as fft\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy import signal\n",
    "import glob\n",
    "import librosa.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws20_classes = [\n",
    "    'up', 'down', 'left', 'right',\n",
    "    'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine',\n",
    "    'on', 'off', 'stop', 'go', 'yes', 'no']\n",
    "    \n",
    "data = '../data/KWS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and normalizing train dataset\n",
    "if load_train:\n",
    "    train_transform = transforms.Compose([\n",
    "        ToMFCC(),\n",
    "        transforms.ToTensor(),\n",
    "        ai8x.normalize(args=args)\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=train_path,\n",
    "                                                        transform=train_transform)\n",
    "else:\n",
    "    train_dataset = None\n",
    "\n",
    "# Loading and normalizing test dataset\n",
    "if load_test:\n",
    "    test_transform = transforms.Compose([\n",
    "        ToMFCC(),\n",
    "        transforms.ToTensor(),\n",
    "        ai8x.normalize(args=args)\n",
    "    ])\n",
    "\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root=test_path,\n",
    "                                                    transform=test_transform)\n",
    "\n",
    "    if args.truncate_testset:\n",
    "        test_dataset.data = test_dataset.data[:1]\n",
    "else:\n",
    "    test_dataset = None\n",
    "\n",
    "return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kwsmlp_dataset(data, load_train=True, load_test=True):\n",
    "    path = os.path.join(data, 'raw')\n",
    "    is_dir = os.path.isdir(path)\n",
    "    if not is_dir:\n",
    "        print(\"******************************************\")\n",
    "        print(\"Please follow the instructions below:\")\n",
    "        print(\"Download the dataset to the \\'data\\' folder by visiting this link: \"\n",
    "              \"\\'https://www.kaggle.com/datasets/salader/dogs-vs-cats\\'\")\n",
    "        print(\"If you do not have a Kaggle account, sign up first.\")\n",
    "        print(\"Unzip the downloaded file and find \\'test\\' and \\'train\\' folders \"\n",
    "              \"and copy them into \\'data/cats_vs_dogs\\'. \")\n",
    "        print(\"Make sure that images are in the following directory structure:\")\n",
    "        print(\"  \\'data/cats_vs_dogs/train/cats\\'\")\n",
    "        print(\"  \\'data/cats_vs_dogs/train/dogs\\'\")\n",
    "        print(\"  \\'data/cats_vs_dogs/test/cats\\'\")\n",
    "        print(\"  \\'data/cats_vs_dogs/test/dogs\\'\")\n",
    "        print(\"Re-run the script. The script will create an \\'augmented\\' folder \")\n",
    "        print(\"with all the original and augmented images. Remove this folder if you want \"\n",
    "              \"to change the augmentation and to recreate the dataset.\")\n",
    "        print(\"******************************************\")\n",
    "        sys.exit(\"Dataset not found!\")\n",
    "    else:\n",
    "        processed_dataset_path = os.path.join(data, \"train_test_split\")\n",
    "        if os.path.isdir(processed_dataset_path):\n",
    "            print(\"train test split folder exits. Remove if you want to regenerate\")\n",
    "\n",
    "        train_path = os.path.join(processed_dataset_path, \"train\")\n",
    "        test_path = os.path.join(processed_dataset_path, \"test\")\n",
    "\n",
    "        if not os.path.isdir(processed_dataset_path):\n",
    "            os.makedirs(processed_dataset_path, exist_ok=True)\n",
    "            os.makedirs(train_path, exist_ok=True)\n",
    "            os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "            # create label folders for training\n",
    "            for d in kws20_classes:\n",
    "                mk = os.path.join(train_path, d)\n",
    "                try:\n",
    "                    os.mkdir(mk)\n",
    "                except OSError as e:\n",
    "                    if e.errno == errno.EEXIST:\n",
    "                        print(f'{mk} already exists!')\n",
    "                    else:\n",
    "                        raise\n",
    "            \n",
    "            # create label folders for test\n",
    "            for d in kws20_classes:\n",
    "                mk = os.path.join(test_path, d)\n",
    "                try:\n",
    "                    os.mkdir(mk)\n",
    "                except OSError as e:\n",
    "                    if e.errno == errno.EEXIST:\n",
    "                        print(f'{mk} already exists!')\n",
    "                    else:\n",
    "                        raise\n",
    "\n",
    "            for folders in kws20_classes:\n",
    "                folder_path=os.path.join(root_dir, folders)\n",
    "                for file in os.listdir(folder_path):\n",
    "                    file_path=os.path.join(folder_path, file)\n",
    "                    temp.append(file_path)\n",
    "                training_data, testing_data = train_test_split(temp, test_size=0.30, random_state=25)\n",
    "                for i in training_data:\n",
    "                    audio, sample_rate = librosa.load(i, sr=16000)\n",
    "                    audio=librosa.util.fix_length(audio, sample_rate)\n",
    "                    test = i.split('raw/')\n",
    "                    detination=test[0] + 'train_test_split/train/'+test[1]\n",
    "                    scipy.io.wavfile.write(filename=detination, rate=sample_rate, data=np.asarray(audio))\n",
    "                for i in testing_data:\n",
    "                    audio, sample_rate = librosa.load(i, sr=16000)\n",
    "                    audio=librosa.util.fix_length(audio, sample_rate)\n",
    "                    test = i.split('raw/')\n",
    "                    detination=test[0] + 'train_test_split/test/'+test[1]\n",
    "                    scipy.io.wavfile.write(filename=detination, rate=sample_rate, data=np.asarray(audio))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c9827bb4e1b969648aed146f7e15ea6993cc5eb0ab76739a03b25ba55c49c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
